#!/usr/bin/env python3
"""
Fetch and parse agenda HTML for recent LA City Council meetings.

This script:
1. Reads meeting data from recent_meetings.json (generated by fetch_meetings.py)
2. Downloads HTML agendas from portal URLs
3. Parses them into structured JSON
4. Saves parsed agendas to data/agendas/
"""

import os
import json
import sys
from typing import Dict, List
from fetch_meetings import LACouncilScraper
from parse_agenda import AgendaParser


def ensure_data_dir():
    """Create data/agendas directory if it doesn't exist."""
    os.makedirs('data/agendas', exist_ok=True)


def parse_meeting_agenda(scraper: LACouncilScraper, meeting: Dict) -> bool:
    """
    Download and parse a single meeting's agenda.

    Args:
        scraper: Configured LACouncilScraper instance
        meeting: Meeting data dict from API

    Returns:
        True if successful, False otherwise
    """
    meeting_id = meeting.get('id')
    date = meeting.get('date', 'Unknown')

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ Meeting {meeting_id} ({date})")
    print(f"{'='*60}\n")

    # Get portal URL
    portal_url = scraper.get_agenda_portal_url(meeting)
    if not portal_url:
        print(f"âš ï¸  No HTML Agenda available for this meeting")
        return False

    print(f"ğŸ”— Portal URL: {portal_url}")

    # Extract template ID from URL
    try:
        template_id = int(portal_url.split('meetingTemplateId=')[1])
    except (IndexError, ValueError):
        print(f"âŒ Could not extract template ID from URL")
        return False

    # Download HTML
    print(f"ğŸ“¥ Downloading agenda HTML...")
    html_content = scraper.fetch_document_content(portal_url)

    if not html_content:
        print(f"âŒ Failed to download agenda")
        return False

    print(f"âœ… Downloaded {len(html_content):,} bytes")

    # Parse HTML
    print(f"ğŸ” Parsing agenda structure...")
    parser = AgendaParser(html_content, meeting_id, template_id)
    agenda = parser.parse()

    print(f"âœ… Parsed {agenda['total_items']} items in {agenda['total_sections']} sections")

    # Save parsed JSON
    output_file = f"data/agendas/agenda_{meeting_id}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(agenda, f, indent=2, ensure_ascii=False)

    print(f"ğŸ’¾ Saved to {output_file}")

    return True


def main():
    """Main function to parse agendas from recent meetings."""

    print("=" * 60)
    print("LA Council Agenda Parser")
    print("=" * 60)
    print()

    # Ensure output directory exists
    ensure_data_dir()

    # Read meetings from recent_meetings.json
    meetings_file = 'recent_meetings.json'
    if not os.path.exists(meetings_file):
        print(f"âŒ Error: {meetings_file} not found!")
        print("   Run 'python fetch_meetings.py' first to fetch meetings.")
        sys.exit(1)

    with open(meetings_file, 'r') as f:
        meetings = json.load(f)

    print(f"ğŸ“‹ Found {len(meetings)} meetings to process\n")

    # Initialize scraper
    scraper = LACouncilScraper()

    # Parse each meeting
    success_count = 0
    skip_count = 0

    for i, meeting in enumerate(meetings, 1):
        meeting_id = meeting.get('id')

        # Check if already parsed
        output_file = f"data/agendas/agenda_{meeting_id}.json"
        if os.path.exists(output_file):
            # Check if we should re-parse (missing video URL for a past meeting)
            should_reparse = False
            try:
                with open(output_file, 'r') as f:
                    existing = json.load(f)
                    if not existing.get('video_url'):
                        # Check if meeting date has passed
                        from datetime import datetime
                        meeting_date_str = meeting.get('date', '')
                        try:
                            meeting_date = datetime.strptime(meeting_date_str, "%b %d, %Y").date()
                            if meeting_date < datetime.now().date():
                                should_reparse = True
                                print(f"\n[{i}/{len(meetings)}] Meeting {meeting_id}: ğŸ”„ Re-parsing (missing video URL)")
                        except:
                            pass
            except:
                pass

            if not should_reparse:
                print(f"\n[{i}/{len(meetings)}] Meeting {meeting_id}: â­ï¸  Already parsed (skipping)")
                skip_count += 1
                continue

        print(f"\n[{i}/{len(meetings)}]", end=" ")
        if parse_meeting_agenda(scraper, meeting):
            success_count += 1
        else:
            print()

    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š Summary")
    print("=" * 60)
    print(f"âœ… Successfully parsed: {success_count}")
    print(f"â­ï¸  Skipped (already parsed): {skip_count}")
    print(f"âš ï¸  Failed/No agenda: {len(meetings) - success_count - skip_count}")
    print(f"ğŸ“ Agendas saved to: data/agendas/")
    print("=" * 60)


if __name__ == "__main__":
    main()
