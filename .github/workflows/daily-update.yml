name: Daily Council Update

on:
  schedule:
    # Run at 6am PT (2pm UTC) every day
    # LA City Council meetings are typically Tue/Wed/Fri, videos upload within 24hrs
    - cron: '0 14 * * *'

  # Allow manual trigger
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Set up Node.js (for yt-dlp)
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch latest meetings
        run: python fetch_meetings.py

      - name: Check for new meetings with video
        id: check_new
        run: |
          python -c "
          import json
          import os

          # Load meetings
          with open('recent_meetings.json') as f:
              meetings = json.load(f)

          # Load already processed meetings
          processed_file = 'data/processed_meetings.txt'
          processed = set()
          if os.path.exists(processed_file):
              with open(processed_file) as f:
                  processed = set(line.strip() for line in f if line.strip())

          # Find meetings with video that haven't been processed
          new_meetings = []
          for m in meetings:
              if m.get('videoUrl') and str(m['id']) not in processed:
                  new_meetings.append(m)

          if new_meetings:
              print(f'Found {len(new_meetings)} new meeting(s) with video')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write('NEW_MEETING=true\n')
                  f.write(f'MEETING_ID={new_meetings[0][\"id\"]}\n')
          else:
              print('No new meetings with video')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write('NEW_MEETING=false\n')
          "

      - name: Parse agendas
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: python parse_agendas.py

      - name: Download transcript
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: python get_transcripts.py

      - name: Generate AI summary
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python summarize_meeting.py

      - name: Generate site
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: |
          python generate_site.py
          python aggregate_council_files.py
          python generate_councilfile_pages.py

      - name: Mark meeting as processed
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: |
          mkdir -p data
          echo "${{ steps.check_new.outputs.MEETING_ID }}" >> data/processed_meetings.txt

      - name: Commit reddit comment and processed list
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/processed_meetings.txt
          git add "meeting_*_reddit_comment.md" || true
          git commit -m "Add summary for meeting ${{ steps.check_new.outputs.MEETING_ID }}" || true
          git push || true

      - name: Deploy to GitHub Pages
        if: steps.check_new.outputs.NEW_MEETING == 'true'
        run: |
          # Deploy site to gh-pages branch using worktree (avoids checkout conflicts)
          TEMP_DIR=$(mktemp -d)
          cp -r site/* "$TEMP_DIR/"

          # Use a separate directory for gh-pages worktree
          WORKTREE_DIR=$(mktemp -d)

          # Fetch gh-pages or create it
          git fetch origin gh-pages:gh-pages 2>/dev/null || true

          if git show-ref --verify --quiet refs/heads/gh-pages; then
            git worktree add "$WORKTREE_DIR" gh-pages
          else
            git worktree add --detach "$WORKTREE_DIR"
            cd "$WORKTREE_DIR"
            git checkout --orphan gh-pages
            git rm -rf . 2>/dev/null || true
            cd - > /dev/null
          fi

          # Copy site files and commit
          rm -rf "$WORKTREE_DIR"/* 2>/dev/null || true
          cp -r "$TEMP_DIR"/* "$WORKTREE_DIR/"

          cd "$WORKTREE_DIR"
          git add -A
          git commit -m "Deploy site $(date '+%Y-%m-%d %H:%M:%S')" || echo "No changes to commit"
          git push origin gh-pages
          cd - > /dev/null

          # Cleanup
          rm -rf "$TEMP_DIR"
          git worktree remove "$WORKTREE_DIR" --force 2>/dev/null || rm -rf "$WORKTREE_DIR"

      - name: Summary
        run: |
          if [ "${{ steps.check_new.outputs.NEW_MEETING }}" == "true" ]; then
            echo "### New meeting processed: ${{ steps.check_new.outputs.MEETING_ID }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Site updated:** https://councilreader.com" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Reddit comment ready:** Check \`meeting_${{ steps.check_new.outputs.MEETING_ID }}_reddit_comment.md\` in the repo" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Copy-paste to r/losangeles daily discussion thread." >> $GITHUB_STEP_SUMMARY
          else
            echo "### No new meetings to process" >> $GITHUB_STEP_SUMMARY
            echo "Will check again tomorrow." >> $GITHUB_STEP_SUMMARY
          fi
